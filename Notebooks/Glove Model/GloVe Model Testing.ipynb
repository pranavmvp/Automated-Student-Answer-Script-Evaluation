{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('main.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe_test(test):\n",
    "    stop_words = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n",
    "              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n",
    "              'Is','If','While','This']\n",
    "    def text_to_wordlist(text, remove_stop_words=True, stem_words=False):\n",
    "        text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "        text = re.sub(r\"what's\", \"\", text)\n",
    "        text = re.sub(r\"What's\", \"\", text)\n",
    "        text = re.sub(r\"\\'s\", \" \", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "        text = re.sub(r\"can't\", \"cannot \", text)\n",
    "        text = re.sub(r\"n't\", \" not \", text)\n",
    "        text = re.sub(r\"I'm\", \"I am\", text)\n",
    "        text = re.sub(r\" m \", \" am \", text)\n",
    "        text = re.sub(r\"\\'re\", \" are \", text)\n",
    "        text = re.sub(r\"\\'d\", \" would \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "        text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "        text = re.sub(r\" e g \", \" eg \", text)\n",
    "        text = re.sub(r\" b g \", \" bg \", text)\n",
    "        text = re.sub(r\"\\0s\", \"0\", text)\n",
    "        text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "        text = re.sub(r\"e-mail\", \"email\", text)\n",
    "        text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "        text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "        text = re.sub(r\" usa \", \" America \", text)\n",
    "        text = re.sub(r\" USA \", \" America \", text)\n",
    "        text = re.sub(r\" u s \", \" America \", text)\n",
    "        text = re.sub(r\" uk \", \" England \", text)\n",
    "        text = re.sub(r\" UK \", \" England \", text)\n",
    "        text = re.sub(r\"india\", \"India\", text)\n",
    "        text = re.sub(r\"switzerland\", \"Switzerland\", text)\n",
    "        text = re.sub(r\"china\", \"China\", text)\n",
    "        text = re.sub(r\"chinese\", \"Chinese\", text) \n",
    "        text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "        text = re.sub(r\"intially\", \"initially\", text)\n",
    "        text = re.sub(r\"quora\", \"Quora\", text)\n",
    "        text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "        text = re.sub(r\"demonitization\", \"demonetization\", text) \n",
    "        text = re.sub(r\"actived\", \"active\", text)\n",
    "        text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "        text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "        text = re.sub(r\" cs \", \" computer science \", text) \n",
    "        text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "        text = re.sub(r\" iPhone \", \" phone \", text)\n",
    "        text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "        text = re.sub(r\"calender\", \"calendar\", text)\n",
    "        text = re.sub(r\"ios\", \"operating system\", text)\n",
    "        text = re.sub(r\"gps\", \"GPS\", text)\n",
    "        text = re.sub(r\"gst\", \"GST\", text)\n",
    "        text = re.sub(r\"programing\", \"programming\", text)\n",
    "        text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "        text = re.sub(r\"dna\", \"DNA\", text)\n",
    "        text = re.sub(r\"III\", \"3\", text) \n",
    "        text = re.sub(r\"the US\", \"America\", text)\n",
    "        text = re.sub(r\"Astrology\", \"astrology\", text)\n",
    "        text = re.sub(r\"Method\", \"method\", text)\n",
    "        text = re.sub(r\"Find\", \"find\", text) \n",
    "        text = re.sub(r\"banglore\", \"Banglore\", text)\n",
    "        text = re.sub(r\" J K \", \" JK \", text)\n",
    "\n",
    "        text = ''.join([c for c in text if c not in punctuation])\n",
    "\n",
    "        if remove_stop_words:\n",
    "            text = text.split()\n",
    "            text = [w for w in text if not w in stop_words]\n",
    "            text = \" \".join(text)\n",
    "\n",
    "        if stem_words:\n",
    "            text = text.split()\n",
    "            stemmer = SnowballStemmer('english')\n",
    "            stemmed_words = [stemmer.stem(word) for word in text]\n",
    "            text = \" \".join(stemmed_words)\n",
    "\n",
    "        return(text)\n",
    "    \n",
    "    def process_questions(question_list, questions, question_list_name, dataframe):\n",
    "        for question in questions:\n",
    "            question_list.append(text_to_wordlist(str(question)))\n",
    "            if len(question_list) % 100000 == 0:\n",
    "                progress = len(question_list)/len(dataframe) * 100\n",
    "                #print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))\n",
    "            \n",
    "    \n",
    "    test_question1 = []\n",
    "    process_questions(test_question1, test.question1, 'test_question1', test)\n",
    "\n",
    "    test_question2 = []\n",
    "    process_questions(test_question2, test.question2, 'test_question2', test)\n",
    "\n",
    "    test[\"question1\"] = test_question1\n",
    "    test[\"question2\"] = test_question2\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Bush is the president.</td>\n",
       "      <td>The president is George Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question1                     question2\n",
       "test_id                                                             \n",
       "0        George Bush is the president.  The president is George Bush"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'question1': ['George Bush is the president.'], 'question2': ['The president is George Bush']}  \n",
    "df = pd.DataFrame(data)\n",
    "df.index.names = ['test_id']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pickle'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clean_dataframe_test(df)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "feats = ['question1','question2']\n",
    "\n",
    "for f in feats:\n",
    "    test[f] = test[f].astype(str)\n",
    "    \n",
    "# Load Tokenizer\n",
    "\n",
    "X_test_q1 = tokenizer.texts_to_sequences(test['question1'])\n",
    "X_test_q2 = tokenizer.texts_to_sequences(test['question2'])\n",
    "\n",
    "X_test_q1 = pad_sequences(X_test_q1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test_q2 = pad_sequences(X_test_q2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39740527]]\n"
     ]
    }
   ],
   "source": [
    "X_test = [X_test_q1,X_test_q2]\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
